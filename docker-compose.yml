networks:
  myNetwork:
    driver: bridge

services:
  bd-pyspark-jupyter:
    image: quay.io/jupyter/pyspark-notebook:latest
    container_name: pyspark-jupyter-lab
    ports:
      - "8888:8888"
      - "4040:4040"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - SPARK_LOCAL_DIRS=/tmp/spark
      - SPARK_WORKER_DIR=/tmp/spark
      - SPARK_OPTS=--driver-java-options=-Dlog4j.configuration=file:/usr/local/spark/conf/log4j.properties
    volumes:
      - ./data:/home/jovyan/work/data
      - ./notebooks:/home/jovyan/work:rw
    networks:
      - myNetwork
    command: >
      sh -c "pip install kafka-python-ng && pip install pandas s3fs boto3 &&
             start-notebook.sh --NotebookApp.token=''"


  zookeeper:
    image: 'bitnami/zookeeper:latest'
    container_name: zookeeper
    ports:
      - '2181:2181'
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - myNetwork

  # kafka-1:
  #   image: 'bitnami/kafka:latest'
  #   user: root
  #   ports:
  #     - '9092:9092'
  #     - '29092:29092'
  #   environment:
  #     - KAFKA_BROKER_ID=1
  #     - KAFKA_LISTENERS=LISTENER_INTERNAL://kafka-1:9092,LISTENER_EXTERNAL://0.0.0.0:29092
  #     - KAFKA_ADVERTISED_LISTENERS=LISTENER_INTERNAL://kafka-1:9092,LISTENER_EXTERNAL://localhost:29092
  #     - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=LISTENER_INTERNAL:PLAINTEXT,LISTENER_EXTERNAL:PLAINTEXT
  #     - KAFKA_INTER_BROKER_LISTENER_NAME=LISTENER_INTERNAL
  #     - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
  #     - ALLOW_PLAINTEXT_LISTENER=yes
  #   networks:
  #     - myNetwork
  #   volumes:
  #     - ./data:/bitnami/kafka 
  #     - ./Kafka/kafka-1:/bitnami/kafka
  #   depends_on:
  #     - zookeeper
  #   # command: >
  #   #   sh -c "
  #   #   /opt/bitnami/scripts/kafka/entrypoint.sh &&
  #   #   sleep 10 &&
  #   #   kafka-topics.sh --create --topic sales-data --bootstrap-server kafka-1:9092"
  broker:
    image: apache/kafka:latest
    container_name: broker
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://broker:9092,CONTROLLER://broker:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
    networks:
      - myNetwork

    # volumes:
    #   - ./data:/opt/kafka 
    #   - ./Kafka/broker:/opt/kafka
  postgres:
    image: postgres
    container_name: postgres
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=sales
    ports:
      - "5431:5432"
    volumes:
      - ./PostgresData:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - myNetwork

  spark-master:
    image: 'bitnami/spark:latest'
    container_name: spark-master
    ports:
      - '8080:8080'
      - '7077:7077'
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./SparkMaster:/bitnami/spark
    networks:
      - myNetwork

  spark-worker-1:
    image: 'bitnami/spark:latest'
    container_name: spark-worker-1
    ports:
      - '8081:8081'
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./SparkWorker1:/bitnami/spark
    networks:
      - myNetwork
    depends_on:
      - spark-master

  spark-worker-2:
    image: 'bitnami/spark:latest'
    container_name: spark-worker-2
    ports:
      - '8082:8082'
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./SparkWorker2:/bitnami/spark
    networks:
      - myNetwork
    depends_on:
      - spark-master


  superset:
    image: apache/superset:latest
    container_name: apache-superset
    ports:
      - "8088:8088"
    environment:
      SUPERSET_LOAD_EXAMPLES: "true"
      SUPERSET_SECRET_KEY: "thisisasecretkey"
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: sales
    volumes:
      - ./superset:/app/superset_home
    networks:
      - myNetwork
    depends_on:
      - postgres
    command: >
      /bin/sh -c "
      pip install psycopg2-binary &&
      superset db upgrade &&
      superset init &&
      gunicorn --workers 2 --timeout 120 --bind 0.0.0.0:8088 'superset.app:create_app()'
      "
  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./storage:/data
    environment:
      MINIO_ROOT_USER: nguyenhoang
      MINIO_ROOT_PASSWORD: nguyenhoang
    networks:
      - myNetwork
    command: server --console-address ":9001" /data
  